{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import ensemble\n",
    "from sklearn import neighbors\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "# classifiers\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "\n",
    "def preprocess_data(data):\n",
    "    '''\n",
    "    Arguments: Pandas Dataframe (X_train or X_test)\n",
    "    Return: Preprocessed np array\n",
    "    '''\n",
    "    # saving columns and indices since ColumnTransformer removes them\n",
    "    columns = data.columns\n",
    "    index = data.index\n",
    "\n",
    "    # defining categorical and numerical features (and categorical feature value range)\n",
    "    categorical_features = ['sex', 'cp', 'fbs', 'restecg', \n",
    "                             'exang', 'slope', 'ca', 'thal']\n",
    "    categories = [[0,1], [1,2,4], [0,1], [0,1,2], \n",
    "                  [0,1], [1,2,3], [0,1,2,3], [3,6,7]]\n",
    "    numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "\n",
    "    # creating transformers\n",
    "    # categorical_transformer = Pipeline[('onehot', OneHotEncoder())]\n",
    "    # numerical_transformer = Pipeline[('scaler', StandardScaler())]\n",
    "\n",
    "    # creating and applying ColumnTransformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[('num', StandardScaler(), numerical_features),\n",
    "                      ('cat', OneHotEncoder(categories=categories, \n",
    "                                            handle_unknown='ignore'),\n",
    "                       categorical_features)],\n",
    "        n_jobs=-1)\n",
    "\n",
    "    data = preprocessor.fit_transform(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesing\n",
    "## Loading Data in Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0  55.0  1.0  4.0     160.0  289.0  0.0      2.0    145.0    1.0      0.8   \n",
       "1  63.0  0.0  4.0     124.0  197.0  0.0      0.0    136.0    1.0      0.0   \n",
       "2  62.0  0.0  4.0     140.0  268.0  0.0      2.0    160.0    0.0      3.6   \n",
       "3  54.0  1.0  4.0     124.0  266.0  0.0      2.0    109.0    1.0      2.2   \n",
       "4  49.0  1.0  3.0     118.0  149.0  0.0      2.0    126.0    0.0      0.8   \n",
       "\n",
       "   slope   ca  thal  \n",
       "0    2.0  1.0   7.0  \n",
       "1    2.0  0.0   3.0  \n",
       "2    3.0  2.0   3.0  \n",
       "3    2.0  1.0   7.0  \n",
       "4    1.0  3.0   3.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.read_csv('data/train_data.csv').drop([\"Unnamed: 0\"], axis = 1)\n",
    "y_train = pd.read_csv('data/train_labels.csv', header=None).drop([0], axis = 1)\n",
    "X_test = pd.read_csv('data/test_data.csv').drop([\"Unnamed: 0\"], axis = 1)\n",
    "y_test = pd.read_csv('data/test_labels.csv', header=None).drop([0], axis = 1)\n",
    "\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     feature       Score\n",
      "7    thalach  130.638311\n",
      "11        ca   67.494039\n",
      "9    oldpeak   58.660191\n",
      "12      thal   49.734096\n",
      "4       chol   28.444992\n",
      "8      exang   27.189943\n",
      "0        age   14.737128\n",
      "2         cp   12.416770\n",
      "3   trestbps    9.563405\n",
      "1        sex    7.681980\n",
      "6    restecg    6.465654\n",
      "10     slope    5.019455\n",
      "5        fbs    0.105166\n"
     ]
    }
   ],
   "source": [
    "#apply SelectKBest class to extract top 10 best features\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=10)\n",
    "fit = bestfeatures.fit(X_train,y_train)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X_train.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['feature','Score']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(14,'Score'))  #print feature importance order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z-Score Transformation and Label Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    128\n",
      "True     109\n",
      "Name: label, dtype: int64\n",
      "False    32\n",
      "True     28\n",
      "Name: label, dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "X_test = X_test.apply(zscore)\n",
    "X_train = X_train.apply(zscore)\n",
    "y_test.rename(columns = {1:\"label\"}, inplace = True)\n",
    "y_train.rename(columns = {1:\"label\"}, inplace = True)\n",
    "print(y_train[\"label\"].value_counts())\n",
    "print(y_test[\"label\"].value_counts())\n",
    "print(type(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_ordered = featureScores.sort_values(['Score'])[\"feature\"]\n",
    "feat_ordered = feat_ordered.reset_index(drop=True)\n",
    "feats = list(feat_ordered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers\n",
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = list(feat_ordered)\n",
    "test_scores_RF = []\n",
    "roc_scores_RF = []\n",
    "for i in range(len(feat_ordered)):\n",
    "    Xi_train = X_train[feats]\n",
    "    f_list = list(range(1,len(Xi_train.values[0])+1))\n",
    "    parameters = {'max_features': f_list}\n",
    "    #finds best max_features parameter\n",
    "    rf = GridSearchCV(ensemble.RandomForestClassifier(criterion = \"entropy\", \n",
    "                                                          n_estimators = 100), \n",
    "                         parameters, cv = 5, iid = True, \n",
    "                         return_train_score = True, n_jobs=-1)\n",
    "    rf.fit(Xi_train.values, y_train.values.ravel())\n",
    "    test_score = rf.score(X_test[feats].values, y_test.values)\n",
    "    test_scores_RF.insert(0, test_score)\n",
    "    ypred = rf.predict(X_test[feats].values)\n",
    "    roc_score = roc_auc_score(ypred, y_test.values)\n",
    "    roc_scores_RF.insert(0,roc_score)\n",
    "    del feats[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6833333333333333, 0.65, 0.7166666666666667, 0.8166666666666667, 0.8166666666666667, 0.7666666666666667, 0.8, 0.85, 0.8333333333333334, 0.8166666666666667, 0.8666666666666667, 0.8166666666666667, 0.85]\n",
      "[0.6824249165739711, 0.6490545050055618, 0.7154882154882155, 0.82, 0.82, 0.7708333333333334, 0.8009049773755658, 0.8619271445358402, 0.8402777777777778, 0.826674500587544, 0.8687782805429863, 0.826674500587544, 0.8619271445358402]\n"
     ]
    }
   ],
   "source": [
    "print(test_scores_RF)\n",
    "print(roc_scores_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### where the test score of n features is at test_scores_RF[n-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best amount of features based on accuracy: [11]\n",
      "accuracy: 0.8666666666666667\n",
      "\n",
      "\n",
      "Best amount of features based on ROC AUC: [11]\n",
      "score: 0.8687782805429863\n"
     ]
    }
   ],
   "source": [
    "print(\"Best amount of features based on accuracy: \" + \n",
    "      str([i+1 for i, x in enumerate(test_scores_RF) if x == max(test_scores_RF)]))\n",
    "print(\"accuracy: \" + str(max(test_scores_RF)))\n",
    "print('\\n')\n",
    "print(\"Best amount of features based on ROC AUC: \" + \n",
    "      str([i+1 for i, x in enumerate(roc_scores_RF) if x == max(roc_scores_RF)]))\n",
    "print(\"score: \" + str(max(roc_scores_RF)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189.60000000000002\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train)*0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = list(feat_ordered)\n",
    "test_scores_KNN = []\n",
    "roc_scores_KNN = []\n",
    "for i in range(len(feat_ordered)):\n",
    "    Xi_train = X_train[feats]\n",
    "    n_list = list(range(5,185,5))\n",
    "    n_list.insert(0, 1)\n",
    "    n_list.append(189)\n",
    "    parameters = {'n_neighbors': n_list}\n",
    "    kn = GridSearchCV(neighbors.KNeighborsClassifier(), \n",
    "                             parameters, cv = 5, iid = True, \n",
    "                                  return_train_score = True, n_jobs=-1)\n",
    "    kn.fit(Xi_train.values, y_train.values.ravel())\n",
    "    test_score = kn.score(X_test[feats].values, y_test.values)\n",
    "    test_scores_KNN.insert(0, test_score)\n",
    "    ypred = kn.predict(X_test[feats].values)\n",
    "    roc_score = roc_auc_score(ypred, y_test.values)\n",
    "    roc_scores_KNN.insert(0,roc_score)\n",
    "    del feats[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7333333333333333, 0.7333333333333333, 0.7833333333333333, 0.85, 0.85, 0.7833333333333333, 0.8166666666666667, 0.8166666666666667, 0.85, 0.8, 0.8333333333333334, 0.8166666666666667, 0.8166666666666667]\n",
      "[0.7321428571428572, 0.75, 0.8003663003663003, 0.8542857142857142, 0.8542857142857142, 0.791421856639248, 0.826674500587544, 0.82, 0.8619271445358402, 0.813397129186603, 0.8402777777777778, 0.826674500587544, 0.826674500587544]\n"
     ]
    }
   ],
   "source": [
    "print(test_scores_KNN)\n",
    "print(roc_scores_KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best amount of features based on accuracy: [4, 5, 9]\n",
      "accuracy: 0.85\n",
      "\n",
      "\n",
      "Best amount of features based on ROC AUC: [9]\n",
      "score: 0.8619271445358402\n"
     ]
    }
   ],
   "source": [
    "print(\"Best amount of features based on accuracy: \" + \n",
    "      str([i+1 for i, x in enumerate(test_scores_KNN) if x == max(test_scores_KNN)]))\n",
    "print(\"accuracy: \" + str(max(test_scores_KNN)))\n",
    "print('\\n')\n",
    "print(\"Best amount of features based on ROC AUC: \" + \n",
    "      str([i+1 for i, x in enumerate(roc_scores_KNN) if x == max(roc_scores_KNN)]))\n",
    "print(\"score: \" + str(max(roc_scores_KNN)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = list(feat_ordered)\n",
    "test_scores_LR = []\n",
    "roc_scores_LR = []\n",
    "for i in range(len(feat_ordered)):\n",
    "    Xi_train = X_train[feats]\n",
    "    C_list = [10**(-2), 10**(-1), \n",
    "              10**(0), 10**(1), 10**(2), 10**(3)]\n",
    "    parameters = {'C': C_list}\n",
    "    lr = GridSearchCV(linear_model.LogisticRegression(solver='lbfgs'),\n",
    "                          parameters, cv = 5, iid = True, \n",
    "                                  return_train_score = True, n_jobs=-1)\n",
    "    lr.fit(Xi_train.values, y_train.values.ravel())\n",
    "    test_score = lr.score(X_test[feats].values, y_test.values)\n",
    "    test_scores_LR.insert(0, test_score)\n",
    "    ypred = lr.predict(X_test[feats].values)\n",
    "    roc_score = roc_auc_score(ypred, y_test.values)\n",
    "    roc_scores_LR.insert(0,roc_score)\n",
    "    del feats[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75, 0.7333333333333333, 0.7666666666666667, 0.8333333333333334, 0.8333333333333334, 0.85, 0.8333333333333334, 0.8333333333333334, 0.8333333333333334, 0.8333333333333334, 0.8333333333333334, 0.85, 0.85]\n",
      "[0.7514285714285714, 0.75, 0.7875000000000001, 0.8348416289592759, 0.8348416289592759, 0.8542857142857142, 0.8348416289592759, 0.8402777777777778, 0.8402777777777778, 0.8402777777777778, 0.8492822966507176, 0.8619271445358402, 0.8619271445358402]\n"
     ]
    }
   ],
   "source": [
    "print(test_scores_LR)\n",
    "print(roc_scores_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best amount of features based on accuracy: [6, 12, 13]\n",
      "accuracy: 0.85\n",
      "\n",
      "\n",
      "Best amount of features based on ROC AUC: [12, 13]\n",
      "score: 0.8619271445358402\n"
     ]
    }
   ],
   "source": [
    "print(\"Best amount of features based on accuracy: \" + \n",
    "      str([i+1 for i, x in enumerate(test_scores_LR) if x == max(test_scores_LR)]))\n",
    "print(\"accuracy: \" + str(max(test_scores_LR)))\n",
    "print('\\n')\n",
    "print(\"Best amount of features based on ROC AUC: \" + \n",
    "      str([i+1 for i, x in enumerate(roc_scores_LR) if x == max(roc_scores_LR)]))\n",
    "print(\"score: \" + str(max(roc_scores_LR)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM with Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = list(feat_ordered)\n",
    "test_scores_SVM = []\n",
    "roc_scores_SVM = []\n",
    "for i in range(len(feat_ordered)):\n",
    "    Xi_train = X_train[feats]\n",
    "    C_list = [10**(-2), 10**(-1), \n",
    "              10**(0), 10**(1), 10**(2), 10**(3)]\n",
    "    parameters = {'C': C_list}\n",
    "    svmclf = GridSearchCV(svm.SVC(kernel = 'linear'), \n",
    "                            parameters, cv = 5, iid = True,\n",
    "                            return_train_score = True, n_jobs=-1)\n",
    "    svmclf.fit(Xi_train.values, y_train.values.ravel())\n",
    "    test_score = svmclf.score(X_test[feats].values, y_test.values)\n",
    "    test_scores_SVM.insert(0, test_score)\n",
    "    ypred = svmclf.predict(X_test[feats].values)\n",
    "    roc_score = roc_auc_score(ypred, y_test.values)\n",
    "    roc_scores_SVM.insert(0,roc_score)\n",
    "    del feats[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75, 0.7, 0.75, 0.8333333333333334, 0.8333333333333334, 0.85, 0.85, 0.8666666666666667, 0.85, 0.85, 0.8333333333333334, 0.85, 0.8333333333333334]\n",
      "[0.7514285714285714, 0.7222222222222223, 0.7637362637362638, 0.8402777777777778, 0.8402777777777778, 0.8542857142857142, 0.8542857142857142, 0.8851674641148326, 0.8619271445358402, 0.8619271445358402, 0.8492822966507176, 0.8619271445358402, 0.8402777777777778]\n"
     ]
    }
   ],
   "source": [
    "print(test_scores_SVM)\n",
    "print(roc_scores_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best amount of features based on accuracy: [8]\n",
      "accuracy: 0.8666666666666667\n",
      "\n",
      "\n",
      "Best amount of features based on ROC AUC: [8]\n",
      "score: 0.8851674641148326\n"
     ]
    }
   ],
   "source": [
    "print(\"Best amount of features based on accuracy: \" + \n",
    "      str([i+1 for i, x in enumerate(test_scores_SVM) if x == max(test_scores_SVM)]))\n",
    "print(\"accuracy: \" + str(max(test_scores_SVM)))\n",
    "print('\\n')\n",
    "print(\"Best amount of features based on ROC AUC: \" + \n",
    "      str([i+1 for i, x in enumerate(roc_scores_SVM) if x == max(roc_scores_SVM)]))\n",
    "print(\"score: \" + str(max(roc_scores_SVM)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
