{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import ensemble\n",
    "from sklearn import neighbors\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "# classifiers\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "\n",
    "# global variables\n",
    "dataset_file_path = 'data/processed.cleveland.data'\n",
    "\n",
    "def load_data(filename):\n",
    "    '''\n",
    "    Reads specified .csv file and returns an X and y dataframe.\n",
    "    > 0. age\n",
    "    > 1. sex\n",
    "    > 2. chest pain type(4 values)\n",
    "    > 3. resting blood pressure\n",
    "    > 4. serum cholestoral in mg/dl\n",
    "    > 5. fasting blood sugar > 120 mg/dl\n",
    "    > 6. resting electrocardiographic results(values 0, 1, 2)\n",
    "    > 7. maximum heart rate achieved\n",
    "    > 8. exercise induced angina\n",
    "    > 9. oldpeak = ST depression induced by exercise relative to rest\n",
    "    > 10. the slope of the peak exercise ST segment\n",
    "    > 11. number of major vessels(0-3) colored by flourosopy\n",
    "    > 12. thal: 3 = normal, 6 = fixed defect, 7 = reversable defect\n",
    "    > 13. num: 0 = no presence, 4 = present\n",
    "    '''\n",
    "\n",
    "    # reading the data\n",
    "    try:\n",
    "        print(\"Reading .csv\")\n",
    "        data = pd.read_csv(filename, header=None)\n",
    "        print(\"Finished reading .csv\")\n",
    "    except:\n",
    "        print(\"Unable to read .csv\")\n",
    "\n",
    "    # set column names\n",
    "    attributes = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg',\n",
    "                'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'num']\n",
    "    data.columns = attributes\n",
    "\n",
    "    X, y = data.iloc[:, 0:-1], data.iloc[:, -1]\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def preprocess_data(data):\n",
    "    '''\n",
    "    Arguments: Pandas Dataframe (X_train or X_test)\n",
    "    Return: Preprocessed np array\n",
    "    '''\n",
    "    # saving columns and indices since ColumnTransformer removes them\n",
    "    columns = data.columns\n",
    "    index = data.index\n",
    "\n",
    "    # defining categorical and numerical features (and categorical feature value range)\n",
    "    categorical_features = ['sex', 'cp', 'fbs', 'restecg', \n",
    "                             'exang', 'slope', 'ca', 'thal']\n",
    "    categories = [[0,1], [1,2,4], [0,1], [0,1,2], \n",
    "                  [0,1], [1,2,3], [0,1,2,3], [3,6,7]]\n",
    "    numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "\n",
    "    # creating transformers\n",
    "    # categorical_transformer = Pipeline[('onehot', OneHotEncoder())]\n",
    "    # numerical_transformer = Pipeline[('scaler', StandardScaler())]\n",
    "\n",
    "    # creating and applying ColumnTransformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[('num', StandardScaler(), numerical_features),\n",
    "                      ('cat', OneHotEncoder(categories=categories, \n",
    "                                            handle_unknown='ignore'),\n",
    "                       categorical_features)],\n",
    "        n_jobs=-1)\n",
    "\n",
    "    data = preprocessor.fit_transform(data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('data/train_data.csv').drop([\"Unnamed: 0\"], axis = 1)\n",
    "y_train = pd.read_csv('data/train_labels.csv', header=None).drop([0], axis = 1)\n",
    "X_test = pd.read_csv('data/test_data.csv').drop([\"Unnamed: 0\"], axis = 1)\n",
    "y_test = pd.read_csv('data/test_labels.csv', header=None).drop([0], axis = 1)\n",
    "\n",
    "y_test.rename(columns = {1:\"label\"}, inplace = True)\n",
    "y_train.rename(columns = {1:\"label\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     feature       Score\n",
      "7    thalach  130.638311\n",
      "11        ca   67.494039\n",
      "9    oldpeak   58.660191\n",
      "12      thal   49.734096\n",
      "4       chol   28.444992\n",
      "8      exang   27.189943\n",
      "0        age   14.737128\n",
      "2         cp   12.416770\n",
      "3   trestbps    9.563405\n",
      "1        sex    7.681980\n",
      "6    restecg    6.465654\n",
      "10     slope    5.019455\n",
      "5        fbs    0.105166\n"
     ]
    }
   ],
   "source": [
    "#apply SelectKBest class to extract top 10 best features\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=10)\n",
    "fit = bestfeatures.fit(X_train,y_train)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X_train.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['feature','Score']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(14,'Score'))  #print feature importance order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_ordered = featureScores.sort_values(['Score'])[\"feature\"]\n",
    "feat_ordered = feat_ordered.reset_index(drop=True)\n",
    "feats = list(feat_ordered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = list(feat_ordered)\n",
    "test_scores_RF = []\n",
    "for i in range(len(feat_ordered)):\n",
    "    Xi_train = X_train[feats]\n",
    "    f_list = list(range(1,len(Xi_train.values[0])+1))\n",
    "    parameters = {'max_features': f_list}\n",
    "    #finds best max_features parameter\n",
    "    rf = GridSearchCV(ensemble.RandomForestClassifier(criterion = \"entropy\", \n",
    "                                                          n_estimators = 100), \n",
    "                         parameters, cv = 5, iid = True, \n",
    "                         return_train_score = True, n_jobs=-1)\n",
    "    rf.fit(Xi_train.values, y_train.values.ravel())\n",
    "    test_score = rf.score(X_test[feats].values, y_test.values)\n",
    "    test_scores_RF.insert(0, test_score)\n",
    "    del feats[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### where the test score of n features is at test_scores_RF[n-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6333333333333333, 0.6833333333333333, 0.7333333333333333, 0.8, 0.8, 0.8, 0.8, 0.8333333333333334, 0.85, 0.8166666666666667, 0.8333333333333334, 0.8, 0.8333333333333334]\n"
     ]
    }
   ],
   "source": [
    "print(test_scores_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feats = list(feat_ordered)\n",
    "# test_scores_KNN = []\n",
    "# for i in range(len(feat_ordered)):\n",
    "#     Xi_train = X_train[feats]\n",
    "#     parameters = {'n_neighbors': n_list}\n",
    "#     kn = GridSearchCV(neighbors.KNeighborsClassifier(), \n",
    "#                              parameters, cv = 5, iid = True, \n",
    "#                                   return_train_score = True, n_jobs=-1)\n",
    "#     kn.fit(Xi_train.values, y_train.values.ravel())\n",
    "#     test_score = kn.score(X_test[feats].values, y_test.values)\n",
    "#     test_scores_KNN.insert(0, test_score)\n",
    "#     del feats[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feats = list(feat_ordered)\n",
    "# test_scores_LR = []\n",
    "# for i in range(len(feat_ordered)):\n",
    "#     Xi_train = X_train[feats]\n",
    "#     parameters = {'max_features': f_list}\n",
    "#     lr = GridSearchCV(linear_model.LogisticRegression())\n",
    "#     lr.fit(Xi_train.values, y_train.values.ravel())\n",
    "#     test_score = lr.score(X_test[feats].values, y_test.values)\n",
    "#     test_scores_LR.insert(0, test_score)\n",
    "#     del feats[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM with Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feats = list(feat_ordered)\n",
    "# test_scores_SVM = []\n",
    "# for i in range(len(feat_ordered)):\n",
    "#     Xi_train = X_train[feats]\n",
    "#     parameters = {'C': c_list}\n",
    "#     svmclf = GridSearchCV(svm.SVC(kernel = 'linear'), parameters, cv = 5, \n",
    "#                       return_train_score = True, iid = True, n_jobs=-1)\n",
    "#     svmclf.fit(Xi_train.values, y_train.values.ravel())\n",
    "#     test_score = svmclf.score(X_test[feats].values, y_test.values)\n",
    "#     test_scores_SVM.insert(0, test_score)\n",
    "#     del feats[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
